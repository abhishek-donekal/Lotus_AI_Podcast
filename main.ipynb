{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "import openai\n",
    "import pandas as pd\n",
    "from IPython.display import Markdown, display\n",
    "from langchain_experimental.agents import create_csv_agent\n",
    "# from langchain.agents import create_csv_agent\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# client = Open\n",
    "\n",
    "# OPENAI_API_KEY = getpass()\n",
    "# os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
    "\n",
    "openai.api_key = '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'\n",
    "\n",
    "# completion = openai.chat.completions.create(\n",
    "#   model=\"gpt-3.5-turbo\",\n",
    "#   messages=[\n",
    "#     {\"role\": \"system\", \"content\": \"You are a poetic assistant, skilled in explaining complex programming concepts with creative flair.\"},\n",
    "#     {\"role\": \"user\", \"content\": \"Compose a poem that explains the concept of recursion in programming.\"}\n",
    "#   ]\n",
    "# )\n",
    "\n",
    "# print(completion.choices[0].message)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Person1: Hey there, did you hear about the latest news in sports today?\n",
      "\n",
      "Person2: Yes, I did. It's about Vinicius Jr, right? He's been facing some serious challenges with racism in Spain.\n",
      "\n",
      "Person1: That's correct. Despite being a top player for Real Madrid, he's been subjected to racist abuse in Spanish stadiums. It's really sad to see such a talented player going through this.\n",
      "\n",
      "Person2: Absolutely. It's heartbreaking to hear that he's considering his future in football because of the racism he's facing. It's important that he's speaking out against it and fighting for change.\n",
      "\n",
      "Person1: Definitely. Vinicius has been using his platform to raise awareness about racism in football and has been actively involved in anti-racism initiatives. It's commendable how he's standing up against this systemic issue.\n",
      "\n",
      "Person2: I hope the authorities take appropriate action to address the racist incidents he's been facing. No player should have to endure such abuse while doing what they love.\n",
      "\n",
      "Person1: Agreed. It's a reminder that racism has no place in sports or anywhere else. I hope Vinicius continues to stay strong and keep playing the game he loves despite the challenges he's facing.\n",
      "\n",
      "Person2: Absolutely. Let's show our support for Vinicius and stand against racism in all its forms. It's time for a change in the world of sports.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import CSVLoader\n",
    "from langchain.embeddings.sentence_transformer import SentenceTransformerEmbeddings\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "\n",
    "embedding_function = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "loader = CSVLoader(\"sports.csv\", encoding=\"utf-8\")\n",
    "documents = loader.load()\n",
    "\n",
    "db = Chroma.from_documents(documents, embedding_function)\n",
    "retriever = db.as_retriever()\n",
    "\n",
    "template = \"\"\"You are a podcaster, talk like a two person conversation, Person1: podcaster, Person2: Guest about the context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "model = ChatOpenAI()\n",
    "\n",
    "chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "print(chain.invoke(\"talk about todays sports news\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to Silly Tisvern! Ask me anything silly.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'VectorStoreRetriever' object has no attribute 'retrieve'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 17\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSilly Tisvern: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Run the interface\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m \u001b[43msilly_tavern\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[29], line 10\u001b[0m, in \u001b[0;36msilly_tavern\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Retrieve relevant context from your database\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m context \u001b[38;5;241m=\u001b[39m \u001b[43mretriever\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrieve\u001b[49m(query, num_results\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdocument\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Generate a response using the model and the context\u001b[39;00m\n\u001b[0;32m     13\u001b[0m response \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mgenerate_response(prompt\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBased on this: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcontext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m You are a podcaster, talk like a two person conversation, Person1: podcaster, Person2: Guest about the context \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquery\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'VectorStoreRetriever' object has no attribute 'retrieve'"
     ]
    }
   ],
   "source": [
    "\n",
    "def silly_tavern():\n",
    "    print(\"Welcome to Silly Tisvern! Ask me anything silly.\")\n",
    "    while True:\n",
    "        query = input(\"You: \")\n",
    "        if query.lower() in ['exit', 'quit']:\n",
    "            print(\"Silly Tisvern signing off. Bye!\")\n",
    "            break\n",
    "\n",
    "        # Retrieve relevant context from your database\n",
    "        context = retriever.retrieve(query, num_results=1)[0]['document']\n",
    "\n",
    "        # Generate a response using the model and the context\n",
    "        response = model.generate_response(prompt=f\"Based on this: {context}\\n\\n You are a podcaster, talk like a two person conversation, Person1: podcaster, Person2: Guest about the context {query}\")\n",
    "        print(f\"Silly Tisvern: {response}\")\n",
    "\n",
    "# Run the interface\n",
    "silly_tavern()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "agent = create_csv_agent(OpenAI(temperature=0, api_key=\"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\"), \"sports.csv\", verbose=True)\n",
    "\n",
    "gpt4_agent = create_csv_agent(\n",
    "    ChatOpenAI(temperature=0, model_name=\"gpt-4\", api_key=\"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\"), \"sports.csv\", verbose=True\n",
    ")\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langchain'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprompts\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ChatPromptTemplate\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprompts\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SystemMessage, HumanMessagePromptTemplate\n\u001b[1;32m      4\u001b[0m template \u001b[38;5;241m=\u001b[39m ChatPromptTemplate\u001b[38;5;241m.\u001b[39mfrom_messages(\n\u001b[1;32m      5\u001b[0m     [\n\u001b[1;32m      6\u001b[0m         SystemMessage(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m     ]\n\u001b[1;32m     14\u001b[0m )\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'langchain'"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import (\n",
    "    SystemMessagePromptTemplate,\n",
    "    PromptTemplate,\n",
    "    ChatPromptTemplate,\n",
    "    HumanMessagePromptTemplate\n",
    ")\n",
    "\n",
    "system_prompt = \"\"\"You are an expert support agent at {organization_name}. {organization_info}\n",
    "\n",
    "Your task is to answer customer queries related to {organization_name}. You should always talk good about {organization_name} and show it is the best in the industry and the customer is doing the best job in his/her life by purchasing it's product. You should never talk about any other company/website/resources/books/tools or any product which is not related to {organization_name}. You should always promote the {organization_name}'s products. If you don't know any answer, don't try to make up an answer. Just say that you don't know and to contact the company support.\n",
    "The ways to contact company support is: {contact_info}.\n",
    "Don't be overconfident and don't hallucinate. Ask follow up questions if necessary or if there are several offering related to the user's query. Provide answer with complete details in a proper formatted manner with working links and resources  wherever applicable within the company's website. Never provide wrong links.\n",
    "\n",
    "\n",
    "Use the following pieces of context to answer the user's question.\n",
    "\n",
    "----------------\n",
    "\n",
    "{context}\n",
    "{chat_history}\n",
    "Follow up question: \"\"\"\n",
    "\n",
    "\n",
    "def get_prompt():\n",
    "    \"\"\"\n",
    "    Generates prompt.\n",
    "\n",
    "    Returns:\n",
    "        ChatPromptTemplate: Prompt.\n",
    "    \"\"\"\n",
    "    prompt = ChatPromptTemplate(\n",
    "        input_variables=['context', 'question', 'chat_history', 'organization_name', 'organization_info', 'contact_info'],\n",
    "        messages=[\n",
    "            SystemMessagePromptTemplate(\n",
    "                prompt=PromptTemplate(\n",
    "                    input_variables=['context', 'chat_history', 'organization_name', 'organization_info', 'contact_info'],\n",
    "                    template=system_prompt, template_format='f-string',\n",
    "                    validate_template=True\n",
    "                ), additional_kwargs={}\n",
    "            ),\n",
    "            HumanMessagePromptTemplate(\n",
    "                prompt=PromptTemplate(\n",
    "                    input_variables=['question'],\n",
    "                    template='{question}\\nHelpful Answer:', template_format='f-string',\n",
    "                    validate_template=True\n",
    "                ), additional_kwargs={}\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "    return prompt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gemini",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
